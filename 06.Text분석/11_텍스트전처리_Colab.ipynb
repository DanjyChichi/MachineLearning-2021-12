{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoUSmBQ8mb00"
      },
      "source": [
        "# 텍스트 전처리(Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGlh6QMhnJ9a"
      },
      "source": [
        "### 1. 토큰화(Tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUh-vLPsmTr4",
        "outputId": "1c50c709-e6f2-4136-811a-ab4c07e14744"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\td708\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\td708\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByL8CDYDoXCd"
      },
      "source": [
        "#### 1) 단어 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S__wdcV6oPI4"
      },
      "outputs": [],
      "source": [
        "sample = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk3k4bBIpRcA",
        "outputId": "67f8b890-51c8-455b-afe9-fc9379ba26f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "print(word_tokenize(sample))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH9xx5U4pl3A",
        "outputId": "6aa8b6c1-64a0-4d25-f326-672290a163c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "wpt = WordPunctTokenizer()\n",
        "print(wpt.tokenize(sample))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWKDaTHBqF3H",
        "outputId": "c25502c9-4c13-484c-fcae-53e4e191db72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "print(text_to_word_sequence(sample))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVIf_JVPqlfj",
        "outputId": "32fd68b0-acf1-4f09-9b5b-503c552b8247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tok = TreebankWordTokenizer()\n",
        "print(tok.tokenize(sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcEYpbuVrUF5"
      },
      "source": [
        "#### 2) 문장 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG8kkartrAfx",
        "outputId": "bd2116ba-afa7-47c9-f6c2-f328ce859aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
        "print(sent_tokenize(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktLvkPn3r9Ai",
        "outputId": "d4e45f31-c907-4d71-d3c2-75ca70c4da68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['His', 'barber', 'kept', 'his', 'word', '.']\n",
            "['But', 'keeping', 'such', 'a', 'huge', 'secret', 'to', 'himself', 'was', 'driving', 'him', 'crazy', '.']\n",
            "['Finally', ',', 'the', 'barber', 'went', 'up', 'a', 'mountain', 'and', 'almost', 'to', 'the', 'edge', 'of', 'a', 'cliff', '.']\n",
            "['He', 'dug', 'a', 'hole', 'in', 'the', 'midst', 'of', 'some', 'reeds', '.']\n",
            "['He', 'looked', 'about', ',', 'to', 'make', 'sure', 'no', 'one', 'was', 'near', '.']\n"
          ]
        }
      ],
      "source": [
        "for sentence in sent_tokenize(text):\n",
        "    print(word_tokenize(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5xkf3jwsg7A",
        "outputId": "2092247c-914f-4ad5-a162-2514d1ba86f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"Since I'm actively looking for Ph.D. students, I get the same question a dozen times every year.\"]\n"
          ]
        }
      ],
      "source": [
        "text = \"Since I'm actively looking for Ph.D. students, I get the same question a dozen times every year.\"\n",
        "print(sent_tokenize(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEIkDhNvtG0g"
      },
      "source": [
        "- 한글 문장 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ARBCKO8Qs33O"
      },
      "outputs": [],
      "source": [
        "# KSS(Korean Sentence Splitter) 설치\n",
        "#!pip install kss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Alum_CvOtSh6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "������ ��θ� ã�� �� �����ϴ�.\n"
          ]
        }
      ],
      "source": [
        "# KSS(Korean Sentence Splitter) 설치시 메세지를 보고싶지 않을 때\n",
        "!pip install kss > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YzM-00NwvF4",
        "outputId": "8d91d38c-5f77-4c09-e522-f4091f09acfe"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'kss'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3648/3262734745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kss'"
          ]
        }
      ],
      "source": [
        "import kss\n",
        "text = '딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?'\n",
        "print(kss.split_sentences(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0juTbXz200v1"
      },
      "source": [
        "#### 3) 품사(POS: Part-of-speech) 태깅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gYXeSdUyC_n",
        "outputId": "0cc0905e-3d12-4265-ce86-088faf499f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', 'am', 'actively', 'looking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n"
          ]
        }
      ],
      "source": [
        "text = \"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n",
        "print(word_tokenize(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO9TZiCG1eb9",
        "outputId": "f8773a53-a666-41ab-e3ee-e82c05b30a32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIxT4sAl1E8I",
        "outputId": "2326e903-9f37-46c7-ff7a-077ee9710e92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('am', 'VBP'),\n",
              " ('actively', 'RB'),\n",
              " ('looking', 'VBG'),\n",
              " ('for', 'IN'),\n",
              " ('Ph.D.', 'NNP'),\n",
              " ('students', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('and', 'CC'),\n",
              " ('you', 'PRP'),\n",
              " ('are', 'VBP'),\n",
              " ('a', 'DT'),\n",
              " ('Ph.D.', 'NNP'),\n",
              " ('student', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tag import pos_tag\n",
        "pos_tag(word_tokenize(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7mZfPtm3Pqw"
      },
      "source": [
        "- 한글 (KoNLPy: 코엔엘파이)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5iXBL631a_A",
        "outputId": "92f32e9e-3673-43af-f6ca-8277733842a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting Konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from Konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 57.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from Konlpy) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->Konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, Konlpy\n",
            "Successfully installed JPype1-1.3.0 Konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "# KoNLPy 설치\n",
        "!pip install Konlpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiOnhYGE4KxS"
      },
      "source": [
        "##### Okt(Open Korean Text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0DKTtLL3jPE",
        "outputId": "32843af5-c148-418f-d50b-a9a301e4778b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 형태소 분석\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "text = \"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"\n",
        "okt.morphs(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YUNGgox4ccf",
        "outputId": "b133bbc0-a9ca-4804-bda0-803f98964bd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가보다']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "okt.morphs(text, stem=True)     # 용언(동사,형용사)은 어간을 추출함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aAsYD2d4tuG",
        "outputId": "8ace0c1d-6322-40ab-ecf0-684217c45d4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('열심히', 'Adverb'),\n",
              " ('코딩', 'Noun'),\n",
              " ('한', 'Josa'),\n",
              " ('당신', 'Noun'),\n",
              " (',', 'Punctuation'),\n",
              " ('연휴', 'Noun'),\n",
              " ('에는', 'Josa'),\n",
              " ('여행', 'Noun'),\n",
              " ('을', 'Josa'),\n",
              " ('가봐요', 'Verb')]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 품사 부착\n",
        "okt.pos(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37EKyxz35FAX",
        "outputId": "2b41eb98-8c3c-412b-dd6c-b347f6e62c57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['코딩', '당신', '연휴', '여행']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 명사 추출\n",
        "okt.nouns(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB_qlv7S52h8"
      },
      "source": [
        "##### 꼬꼬마"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mlFE5_y5UCC",
        "outputId": "be8817ec-ff31-47de-abc8-2e32809f0d2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가보', '아요']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from konlpy.tag import Kkma\n",
        "kkma = Kkma()\n",
        "kkma.morphs(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-102zbQa6DIG",
        "outputId": "fe876b64-317d-4a55-8735-a476301223f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('열심히', 'MAG'),\n",
              " ('코딩', 'NNG'),\n",
              " ('하', 'XSV'),\n",
              " ('ㄴ', 'ETD'),\n",
              " ('당신', 'NP'),\n",
              " (',', 'SP'),\n",
              " ('연휴', 'NNG'),\n",
              " ('에', 'JKM'),\n",
              " ('는', 'JX'),\n",
              " ('여행', 'NNG'),\n",
              " ('을', 'JKO'),\n",
              " ('가보', 'VV'),\n",
              " ('아요', 'EFN')]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kkma.pos(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUDG1CDO6SU4",
        "outputId": "7c477c53-5ef9-43aa-f792-372827a33fe5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['코딩', '당신', '연휴', '여행']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kkma.nouns(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nopjTi_i6xnM"
      },
      "source": [
        "### 2. 정제(Cleaning)와 정규화(Normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlbZtTow6Y-3"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "text = \"I was wondering if anyone out there could enlighten me on this car.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AfIfnrCV_fqH",
        "outputId": "6bbc36b8-067b-43c6-c987-9c44c19c11f2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' was wondering anyone out there could enlighten this car.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 길이가 1~2인 단어들을 정규 표현식을 이용하여 삭제\n",
        "shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
        "shortword.sub('', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1OA4SWt_ufw",
        "outputId": "16af5760-d36b-4894-9ced-24c50af47189"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['was',\n",
              " 'wondering',\n",
              " 'anyone',\n",
              " 'out',\n",
              " 'there',\n",
              " 'could',\n",
              " 'enlighten',\n",
              " 'this',\n",
              " 'car']"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 단어 토큰화한 후 길이가 2보다 큰 단어만 발췌\n",
        "[word for word in word_tokenize(text) if len(word) > 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MUBLxtxB_114",
        "outputId": "7081c4fe-85c0-44ed-82e0-94a943bb94a6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'was wondering anyone out there could enlighten this car'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_text = ' '.join([word for word in word_tokenize(text) if len(word) > 2])\n",
        "clean_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaRwHhOtBHaD"
      },
      "source": [
        "### 3. 어간 추출(Stemming) 및 표제어 추출(Lemmatization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02tXLos1BWES"
      },
      "source": [
        "#### 1) 표제어 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLzVWkeiAPvn",
        "outputId": "e9ef4a25-cf20-48cb-f0d8-3a775ff4c759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brx8rxMvCBHg"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemma = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q4Dh-3uCSfI",
        "outputId": "99e1f0cc-bbf0-4667-ee8e-e8ca3aa737d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
          ]
        }
      ],
      "source": [
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "print([lemma.lemmatize(word) for word in words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlqtKxJxCube",
        "outputId": "061a387a-3c9b-48a2-efb0-cbbe9cd5c4ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('do', 'die', 'watch', 'have')"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lemma.lemmatize('doing','v'),lemma.lemmatize('dies','v'),lemma.lemmatize('watched','v'),lemma.lemmatize('has','v')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkYyIbaJDbjQ",
        "outputId": "a9403433-1413-4ea9-e3d4-8304dca6369c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('live', 'life')"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lemma.lemmatize('lives','v'),lemma.lemmatize('lives','n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rihV-rtyEC0M"
      },
      "source": [
        "#### 2) 어간 추출(Stemming)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrhZJA9WDr_-"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "text = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbs6QD3CEZrY",
        "outputId": "8bff2a0a-6833-42cf-db9d-e6df5638b750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n"
          ]
        }
      ],
      "source": [
        "# 어간 추출전\n",
        "print(word_tokenize(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q05blfrDEix4",
        "outputId": "30777377-34f6-421c-82fd-b0992ce6b776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
          ]
        }
      ],
      "source": [
        "# 어간 추출후\n",
        "print([ps.stem(word) for word in word_tokenize(text)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7MkGqRsEsWJ",
        "outputId": "962b3086-ce47-4bae-e2b3-8c48818efafd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['formal', 'allow', 'electric']\n"
          ]
        }
      ],
      "source": [
        "words = ['formalize', 'allowance', 'electricical']\n",
        "print([ps.stem(word) for word in words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaIGfchbFUBK",
        "outputId": "06304785-b435-4067-b35c-bf0d74369f41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n"
          ]
        }
      ],
      "source": [
        "# Porter Stemmer\n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "print([ps.stem(word) for word in words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heHlJy8xFn1r",
        "outputId": "71af4633-8bc6-47e4-e70b-e1b5e841d308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
          ]
        }
      ],
      "source": [
        "# Lancaster Stemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "ls = LancasterStemmer()\n",
        "print([ls.stem(word) for word in words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHNuzQlpF5MZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "11.텍스트전처리-Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
